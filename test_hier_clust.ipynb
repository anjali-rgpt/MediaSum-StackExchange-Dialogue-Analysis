{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error unknown url type:\n",
      "[nltk_data]     https>\n",
      "[nltk_data] Error loading punkt: <urlopen error unknown url type:\n",
      "[nltk_data]     https>\n",
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     unknown url type: https>\n",
      "[nltk_data] Error loading stopwords: <urlopen error unknown url type:\n",
      "[nltk_data]     https>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preprocess, topic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'test_cases\\singlelinetestcase3.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(pd.read_json(path))\n",
    "data.reset_index(inplace = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = data['utt'][0]\n",
    "speakers = data['speaker'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR CHAZ ALLEN\n",
      "Status: response\n",
      "\n",
      "Current speaker: MAYOR CHAZ ALLEN\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR CHAZ ALLEN\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR CHAZ ALLEN\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR CHAZ ALLEN\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR CHAZ ALLEN\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR CHAZ ALLEN\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR TOMMY BATTLE\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR TOMMY BATTLE\n",
      "Status: response\n",
      "\n",
      "Current speaker: MAYOR TOMMY BATTLE\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR TOMMY BATTLE\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR CHAZ ALLEN\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR CHAZ ALLEN\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR CHAZ ALLEN\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR CHAZ ALLEN\n",
      "Status: response\n",
      "\n",
      "Current speaker: MAYOR CHAZ ALLEN\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: DAWN\n",
      "Status: response\n",
      "\n",
      "Current speaker: DAWN\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: DAWN\n",
      "Status: response\n",
      "\n",
      "Current speaker: DAWN\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: DAWN\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: DAWN\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR TOMMY BATTLE\n",
      "Status: response\n",
      "\n",
      "Current speaker: MAYOR TOMMY BATTLE\n",
      "Status: response\n",
      "\n",
      "Current speaker: MAYOR TOMMY BATTLE\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR TOMMY BATTLE\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MAYOR TOMMY BATTLE\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: ALEX\n",
      "Status: response\n",
      "\n",
      "Current speaker: ALEX\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: ALEX\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: ALEX\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: ALEX\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: ALEX\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: ALEX\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: BARRY\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: BARRY\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: BARRY\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: BARRY\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MICHELLE\n",
      "Status: response\n",
      "\n",
      "Current speaker: MICHELLE\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MICHELLE\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MICHELLE\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: MICHELLE\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: GROVER\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: GROVER\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: GROVER\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n",
      "\n",
      "Current speaker: RICHARD LONGWORTH\n",
      "Status: response\n",
      "\n",
      "Current speaker: JOHN DONVAN, host\n"
     ]
    }
   ],
   "source": [
    "questions, answers, q_indices, a_indices, qa_pairs = preprocess.question_count(utterances, speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qa_pairs.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_column = qa_pairs.keys()\n",
    "answer_column = qa_pairs.values()\n",
    "\n",
    "qa_df = pd.DataFrame(columns = ['questions', 'answers'])\n",
    "qa_df['questions'] = question_column\n",
    "qa_df['answers'] = answer_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So joining us now from Newton, Iowa by phone, ...</td>\n",
       "      <td>Well, when they finally shut down, we had a ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You you had people who3 were interested in may...</td>\n",
       "      <td>Oh, you bet. You bet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A couple of things. Did Maytag give you warnin...</td>\n",
       "      <td>Not really Maytag, but when they were sold to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So some of it went overseas, then?</td>\n",
       "      <td>You bet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What about, though - I'm wondering if there wa...</td>\n",
       "      <td>No. I think a lot of people - it was. I mean, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0  So joining us now from Newton, Iowa by phone, ...   \n",
       "1  You you had people who3 were interested in may...   \n",
       "2  A couple of things. Did Maytag give you warnin...   \n",
       "3                 So some of it went overseas, then?   \n",
       "4  What about, though - I'm wondering if there wa...   \n",
       "\n",
       "                                             answers  \n",
       "0  Well, when they finally shut down, we had a ch...  \n",
       "1                              Oh, you bet. You bet.  \n",
       "2  Not really Maytag, but when they were sold to ...  \n",
       "3                                           You bet.  \n",
       "4  No. I think a lot of people - it was. I mean, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the questions for topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import create_pipeline\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer_model = spacy.load('en_core_web_sm', disable = ['ner', 'parser'])\n",
    "stopword_eng = stopwords.words('english')\n",
    "contractions_dict = {\"aren t\" : \"are not\", \"can t\" : \"cannot\", \"couldnt\":\"could not\", \"couldn t\" : \"could not\", \"didn t\" : \"did not\", \"doesn t\" : \"does not\", \"don t\" : \"do not\", \"haven t\" : \"have not\", \"hasn t\" : \"has not\" , \"hadn t\" : \"had not\", \"i m\" : \"i am\", \"i ve\" : \"i have\", \"isn t\" : \"is not\", \"it's\" : \"it is\" , \"mustn t\" : \"must not\", \"shouldn t\" : \"should not\", \"wasn t\" : \"was not\", \"weren t\" : \"were not\", \"wouldn t\" : \"would not\", \"won t\":\"will not\", \"you re\" : \"you are\", \"you ll\" : \"you will\" , \"we ll\" : \"we will\", \"you ve\" : \"you have\", \"we ve\" : \"we have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df['regular_split'] = qa_df['questions'].apply(lambda x: create_pipeline(x, ['norm', 'tags'], relevant_tags = ['NN', 'VB', 'JJ', 'NNP', 'NNS', 'JJR'], general_category = False))\n",
    "qa_df['Preprocessed_Question'] = qa_df['questions'].apply(lambda x: create_pipeline(x, ['norm', 'ctrc', 'tags', 'stop', 'lemm', 'norm'], relevant_tags = ['NN', 'VB', 'JJ', 'RB'], stopwords=stopword_eng, lemmatizer = lemmatizer_model, contractions = contractions_dict, general_category = True, keep_nonascii = False, lowercase = True, word_length = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>regular_split</th>\n",
       "      <th>Preprocessed_Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So joining us now from Newton, Iowa by phone, ...</td>\n",
       "      <td>Well, when they finally shut down, we had a ch...</td>\n",
       "      <td>[newton, iowa, phone, mayor, chaz, allen, hunt...</td>\n",
       "      <td>[join, newton, iowa, phone, mayor, chaz, allen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You you had people who3 were interested in may...</td>\n",
       "      <td>Oh, you bet. You bet.</td>\n",
       "      <td>[people, interested, fashion, other]</td>\n",
       "      <td>[people, interested, maybe, come, help, fashion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A couple of things. Did Maytag give you warnin...</td>\n",
       "      <td>Not really Maytag, but when they were sold to ...</td>\n",
       "      <td>[couple, things, give]</td>\n",
       "      <td>[couple, thing, maytag, give, warning, come]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So some of it went overseas, then?</td>\n",
       "      <td>You bet.</td>\n",
       "      <td>[]</td>\n",
       "      <td>[go, overseas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What about, though - I'm wondering if there wa...</td>\n",
       "      <td>No. I think a lot of people - it was. I mean, ...</td>\n",
       "      <td>[i, sense, betrayal, year, history, i, people,...</td>\n",
       "      <td>[wonder, sense, betrayal, give, year, history,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0  So joining us now from Newton, Iowa by phone, ...   \n",
       "1  You you had people who3 were interested in may...   \n",
       "2  A couple of things. Did Maytag give you warnin...   \n",
       "3                 So some of it went overseas, then?   \n",
       "4  What about, though - I'm wondering if there wa...   \n",
       "\n",
       "                                             answers  \\\n",
       "0  Well, when they finally shut down, we had a ch...   \n",
       "1                              Oh, you bet. You bet.   \n",
       "2  Not really Maytag, but when they were sold to ...   \n",
       "3                                           You bet.   \n",
       "4  No. I think a lot of people - it was. I mean, ...   \n",
       "\n",
       "                                       regular_split  \\\n",
       "0  [newton, iowa, phone, mayor, chaz, allen, hunt...   \n",
       "1               [people, interested, fashion, other]   \n",
       "2                             [couple, things, give]   \n",
       "3                                                 []   \n",
       "4  [i, sense, betrayal, year, history, i, people,...   \n",
       "\n",
       "                               Preprocessed_Question  \n",
       "0  [join, newton, iowa, phone, mayor, chaz, allen...  \n",
       "1   [people, interested, maybe, come, help, fashion]  \n",
       "2       [couple, thing, maytag, give, warning, come]  \n",
       "3                                     [go, overseas]  \n",
       "4  [wonder, sense, betrayal, give, year, history,...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word count: 1366\n"
     ]
    }
   ],
   "source": [
    "count_words = np.sum(qa_df['questions'].apply(lambda x: preprocess.word_count(x)))\n",
    "print(\"Total word count:\", count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               ngram        pmi\n",
      "0          (affairs, author, caught)  17.469419\n",
      "16              (idea, first, place)  17.469419\n",
      "1           (author, caught, middle)  17.469419\n",
      "30  (unfortunate, curve, government)  17.469419\n",
      "29   (tough, difficult, humiliating)  17.469419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Internship_Task\\NewsTranscriptsTask\\transcriptanalysis\\preprocess.py:355: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  tagged_list = ngram_df[to_keep][ngram_df['pmi'] > min_pmi]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ngram      pmi\n",
      "0   (affairs, author)  8.73471\n",
      "48   (rapids, moment)  8.73471\n",
      "56  (sort, struggles)  8.73471\n",
      "55   (somehow, doesn)  8.73471\n",
      "54     (solar, panel)  8.73471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Internship_Task\\NewsTranscriptsTask\\transcriptanalysis\\preprocess.py:355: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  tagged_list = ngram_df[to_keep][ngram_df['pmi'] > min_pmi]\n"
     ]
    }
   ],
   "source": [
    "trigrams, _ = preprocess.generate_ngrams(qa_df, 'regular_split', n = 3, min_pmi = 10, frequency = 1, best_number = 25, stopwords_list = stopword_eng)\n",
    "bigrams, _ = preprocess.generate_ngrams(qa_df, 'regular_split', n = 2, min_pmi = 8, frequency = 1, best_number = 5, stopwords_list = stopword_eng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16                    (idea, first, place)\n",
       "1                 (author, caught, middle)\n",
       "30        (unfortunate, curve, government)\n",
       "29         (tough, difficult, humiliating)\n",
       "28                   (terms, ready, world)\n",
       "27               (tell, stories, continue)\n",
       "26                 (solar, panel, factory)\n",
       "25                 (same, sort, struggles)\n",
       "24           (rapids, moment, interesting)\n",
       "23               (place, rest, assumption)\n",
       "21             (middle, phenomena, member)\n",
       "20                 (member, station, wbez)\n",
       "19    (manufacturing, american, byproduct)\n",
       "18        (issue, manufacturing, american)\n",
       "17                   (insane, idea, first)\n",
       "22            (phenomena, member, station)\n",
       "15                 (grand, rapids, moment)\n",
       "8               (country, years, frontier)\n",
       "14               (global, affairs, author)\n",
       "3           (bulldozers, afternoon, knock)\n",
       "4              (caught, middle, phenomena)\n",
       "5           (change, immediate, aftermath)\n",
       "6                     (cold, terms, ready)\n",
       "7               (council, global, affairs)\n",
       "9                   (couple, things, give)\n",
       "Name: ngram, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = list(trigrams) + list(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qa_df['questions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Conda\\envs\\newenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "n_wd_ngrams = np.empty((len(ngrams), len(qa_df['questions'])))\n",
    "\n",
    "for i in range(len(ngrams)):\n",
    "    for j in range(len(qa_df['questions'])):\n",
    "        # print(ngrams[i])\n",
    "        n_wd_ngrams[i][j] = qa_df.loc[j, 'questions'].count(' '.join(ngrams[i]))\n",
    "        \n",
    "cv = CountVectorizer(max_features = 32, stop_words='english')\n",
    "n_wd = np.array(cv.fit_transform(qa_df['questions']).todense()).T\n",
    "vocabulary = cv.get_feature_names()\n",
    "\n",
    "n_wd = np.concatenate((n_wd, n_wd_ngrams))\n",
    "ngrams = [' '.join(x) for x in ngrams]\n",
    "vocabulary += ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['allen',\n",
       " 'barry',\n",
       " 'best',\n",
       " 'bring',\n",
       " 'city',\n",
       " 'community',\n",
       " 'company',\n",
       " 'did',\n",
       " 'does',\n",
       " 'feel']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Topic Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==3.0.0 in c:\\users\\anjali ragupathi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anjali ragupathi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from protobuf==3.0.0) (59.5.0)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\anjali ragupathi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from protobuf==3.0.0) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anjali ragupathi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\anjali ragupathi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install protobuf==3.0.0\n",
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! set PATH=%PATH%;D:\\Conda\\envs\\newenv\\Lib\\BigARTM\\bigartm-0.10.1\\bin\n",
    "# ! set PYTHONPATH=%PYTHONPATH%;D:\\Conda\\envs\\newenv\\Lib\\BigARTM\\bigartm-0.10.1\\python\n",
    "# ! cd D:\\Conda\\envs\\newenv\\Lib\\BigARTM\\bigartm-0.10.1\\python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'artm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-513ce4935e65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0martm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'artm'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b2a0cb87e47d8fdb1d7fbe1402e967e24b280003558e33dd11467eb88ce90f0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('newenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
